% Part: first-order-logic
% Chapter: sequent-calculus
% Section: rules-and-proofs

\documentclass[../../include/open-logic-section]{subfiles}

\begin{document}

\olfileid{fol}{seq}{rul}

\olsection{Rules and \usetoken{P}{derivation}}

Let $\Lang L$ be a first-order language with the usual constants,
!!{variable}s, logical symbols, and auxiliary symbols (parentheses
and the comma).

\begin{defn}[sequent]
A \emph{sequent} is an expression of the form
\[ \Gamma \Sequent \Delta \]
where $\Gamma$ and $\Delta$ are finite (possibly empty) sets of
!!{sentence}s of the language $\Lang L$. The !!{formula}s in $\Gamma$
are the \emph{antecedent !!{formula}s}, while the formulae in $\Delta$ are
the \emph{succedent !!{formula}s}.

The intuitive idea behind a sequent is: if all of the antecedent
!!{formula}s hold, then at least one of the succedent !!{formula}s
holds. That is, if $\Gamma = \{ \Gamma_1, \dots, \Gamma_m\}$ and
$\Delta = \{ \Delta_1, \dots, \Delta_n\}$, then $\Gamma \Sequent
\Delta$ holds iff
\[ 
(\Gamma_1 \land \cdots \land \Gamma_m) \lif (\Delta_1 \lor \cdots \lor
\Delta_n) \] holds.

When $m=0$, $\quad \Sequent \Delta$ holds iff $\Delta_1 \lor \dots
\lor \Delta_n$ holds. When $n=0$, $\Gamma \Sequent \quad$ holds iff
$\Gamma_1 \land \dots \land \Gamma_m$ does not. An empty succedent is
sometimes filled with the $\lfalse$ symbol. The empty sequent
$\quad \Sequent \quad$ canonically represents a
contradiction.
\end{defn}

We write $\Gamma, !A$ (or $!A, \Gamma$) for $\Gamma \cup \{!A\}$, and
$\Gamma, \Delta$ for $\Gamma \cup \Delta$.

\begin{defn}[Inference]
An \emph{inference} is an expression of the form
\[
\AxiomC{$S_1$}
\UnaryInfC{$S$}
\DisplayProof
\quad
\textrm{  or  }
\quad
\AxiomC{$S_1$}
\AxiomC{$S_2$}
\BinaryInfC{$S$}
\DisplayProof
\]
where $S, S_1$, and $S_2$ are sequents. $S_1$ and $S_2$ are called the
\emph{upper sequents} and $S$ the \emph{lower sequent} of the
inference.

Inferences represent the idea that whenever the upper sequent(s) is
(are) asserted, from it, we may logically infer the lower sequent.
\end{defn}

For the following, let $\Gamma, \Delta, \Pi, \Lambda$ represent finite
sets of !!{sentence}s.

The rules for $\Log{LK}$ are divided into two main types:
\emph{structural} rules and \emph{logical} rules. The logical rules
are further divided into \emph{propositional} rules (quantifier-free)
and \emph{quantifier} rules.

\paragraph{Structural rules:}

Weakening:
\[
\Axiom$ \Gamma \fCenter \Delta $
\UnaryInf$ !A, \Gamma \fCenter \Delta$
\DisplayProof
\quad
\textrm{  and  }
\quad
\Axiom$ \Gamma \fCenter \Delta$
\UnaryInf$ \Gamma \fCenter \Delta, !A$
\DisplayProof
\]
where $!A$ is called the \emph{weakening !!{formula}}.

Cut:
\[
\Axiom$ \Gamma \fCenter \Delta, !A$
\Axiom$ !A, \Pi \fCenter \Lambda $
\BinaryInf$ \Gamma, \Pi \fCenter \Delta, \Lambda$
\DisplayProof
\]

\paragraph{Logical rules:}

The rules are named by the !!{main operator} of the \emph{principal
  !!{formula}} of the inference (the formula containing $!A$ and/or
$!B$ in the lower sequent). The designations ``left'' and ``right''
indicate whether the logical symbol has been introduced in an
antecedent formula or a succedent formula (to the left or to the right
of the sequent symbol).

\emph{Propositional Rules:}
\[
\Axiom$ \Gamma \fCenter \Delta, !A $
\RightLabel{$\lnot$ left}
\UnaryInf$ \lnot !A, \Gamma \fCenter \Delta$
\DisplayProof
\quad
\Axiom$!A, \Gamma \fCenter \Delta$
\RightLabel{$\lnot$ right}
\UnaryInf$ \Gamma \fCenter \Delta, \lnot !A $
\DisplayProof
\]

\[
\Axiom$ !A, \Gamma \fCenter \Delta$
\RightLabel{$\land$ left}
\UnaryInf$ !A \land !B, \Gamma \fCenter \Delta$
\DisplayProof
\quad
\Axiom$!B, \Gamma \fCenter \Delta$
\RightLabel{$\land$ left}
\UnaryInf$!A \land !B, \Gamma \fCenter \Delta$
\DisplayProof
\quad
\Axiom$\Gamma \fCenter \Delta, !A$
\Axiom$ \Gamma \fCenter \Delta, !B$
\RightLabel{$\land$ right}
\BinaryInf$ \Gamma \fCenter \Delta, !A \land !B $
\DisplayProof
\]

\[
\Axiom$!A,\Gamma\fCenter \Delta$
\Axiom$ !B, \Gamma \fCenter \Delta$
\RightLabel{$\lor$ left}
\BinaryInf$ !A \lor !B, \Gamma \fCenter \Delta$
\DisplayProof
\quad
\Axiom$\Gamma \fCenter \Delta, !A$
\RightLabel{$\lor$ right}
\UnaryInf$ \Gamma \fCenter \Delta, !A \lor !B$
\DisplayProof
\quad
\Axiom$ \Gamma \fCenter \Delta, !B$
\RightLabel{$\lor$ right}
\UnaryInf$ \Gamma \fCenter \Delta, !A \lor !B$
\DisplayProof
\]

\[
\Axiom$ \Gamma \fCenter \Delta, !A$
\Axiom$ !B, \Pi \fCenter \Lambda$
\RightLabel{$\lif$ left}
\BinaryInf$ !A \lif !B, \Gamma, \Pi \fCenter \Delta, \Lambda$
\DisplayProof
\quad
\Axiom$ !A, \Gamma \fCenter \Delta, !B$
\RightLabel{$\lif$ right}
\UnaryInf$ \Gamma \fCenter \Delta, !A \lif !B $
\DisplayProof
\]

\emph{Quantifier Rules:}

\[
\Axiom$ !A(t), \Gamma \fCenter \Delta$
\RightLabel{$\lforall$ left}
\UnaryInf$ \lforall[x][!A(x)],\Gamma \fCenter \Delta$
\DisplayProof
\quad
\Axiom$ \Gamma \fCenter \Delta, !A(a) $
\RightLabel{$\lforall$ right}
\UnaryInf$ \Gamma \fCenter \Delta, \lforall[x][!A(x)]$
\DisplayProof
\]
where $t$ is a ground term (i.e., one without variables), and $a$~is a
constant which does not occur anywhere in the lower sequent of the
$\lforall$ right rule. We call $a$ the \emph{eigenvariable} of the
$\forall$ right inference.

\[
\Axiom$ !A(a), \Gamma \fCenter \Delta $
\RightLabel{$\lexists$ left}   
\UnaryInf$ \lexists[x][!A(x)], \Gamma \fCenter \Delta$
\DisplayProof
\quad
\Axiom$ \Gamma \fCenter \Delta, !A(t) $
\RightLabel{$\lexists$ right}
\UnaryInf$ \Gamma \fCenter \Delta, \lexists[x][!A(x)]$
\DisplayProof
\]
where $t$ is a ground term, and $a$ is a constant which does not occur
in the lower sequent of the $\lexists$ left rule. We call $a$
the \emph{eigenvariable} of the $\lexists$ left inference.

The condition that an eigenvariable not occur in the upper sequent of
the $\lforall$ right or $\lexists$ left inference is called the
\emph{eigenvariable condition}.

\begin{explain}
We use the term ``eigenvariable'' even though $a$ in the above rules
is a constant. This has historical reasons.

In $\lexists$ right and $\lforall$ left there are no restrictions, and
the term~$t$ can be anything, so we do not have to worry about any
conditions.  However, because the $t$ may appear elsewhere in the
sequent, the values of~$t$ for which the sequent is satisfied are
constrained. On the other hand, in the $\lexists$ left and $\lforall$
right rules, the eigenvariable condition requires that $a$ does not
occur anywhere else in the sequent. Thus, if the upper sequent is
valid, the truth values of the formulas other than $!A(a)$ are
independent of~$a$.
\end{explain}

\begin{defn}[Initial Sequent]
An \emph{initial sequent} is a sequent of the form $!A \Sequent !A$
for any !!{sentence} $!A$ in the language.
\end{defn}

\begin{defn}[LK !!{derivation}]
An \emph{$\Log{LK}$-!!{derivation}} of a sequent $S$ is a tree of sequents
satisfying the following conditions:
\begin{enumerate}
\item The topmost sequents of the tree are initial sequents.
\item Every sequent in the tree (except $S$) is an upper sequent of an
  inference whose lower sequent stands directly below that sequent in
  the tree.
\end{enumerate}
We then say that $S$ is the \emph{end-sequent} of the !!{derivation} and
that $S$ is \emph{!!{derivable} in $\Log{LK}$} (or $\Log{LK}$-!!{derivable}).
\end{defn}

\begin{defn}[LK theorem]
!!^a{sentence} $!A$ is a \emph{theorem} of $\Log{LK}$ if the sequent
$\quad \Sequent !A$ is $\Log{LK}$-!!{derivable}.
\end{defn}

\end{document}
